[["additional-examples.html", "3 Additional example applications 3.1 Selection bias 3.2 Misclassification 3.3 Unmeasured confounding", " 3 Additional example applications We will present here examples of quantitative bias analysis using simulated participant-level data for a cohort study with a binary treatment, binary outcome, and binary confounder. # load packages require(tidyverse) require(ggplot2) library(broom) library(janitor) 3.1 Selection bias In the simulated data we have a binary treatment \\(a\\), binary confounder \\(x\\), outcome \\(y\\), and a binary indicator for selection into the study \\(s\\). sim_data &lt;- read_csv(&quot;data/simulated_data.csv&quot;) %&gt;% select(x,a,y,s) sim_data %&gt;% head(5) ## # A tibble: 5 Ã— 4 ## x a y s ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0 0 0 1 ## 2 0 0 0 1 ## 3 0 0 0 1 ## 4 0 0 0 1 ## 5 0 0 0 1 The data was generated such that the causal odds ratio between treatment and outcome was 2. However, in a given sample the estimate may differ due to random error. If we observed a random sample from the target population we could unbiasedly estimate the odds ratio using logistic regression. # fit logistic regression model lgr_model &lt;- glm(y ~ x + a, data=sim_data, family=&quot;binomial&quot;) # tidy model outputs or &lt;- lgr_model %&gt;% tidy(exponentiate=TRUE, conf.int=TRUE) %&gt;% filter(term == &quot;a&quot;) %&gt;% select(estimate, conf.low, conf.high) # output as table or %&gt;% knitr::kable(caption = &quot;Estimated odds ratio&quot;) Table 3.1: Estimated odds ratio estimate conf.low conf.high 2.040021 1.942229 2.142647 However, if we consider that selection into the study was dependent on exposure and outcome and that we only observed a selected subsample of the target population, then the estimated odds ratio is biased. # restrict data to selected subsample selected_data &lt;- sim_data %&gt;% filter(s == 1) # fit logistic regression model lgr_model_selected &lt;- glm(y ~ x + a, data=selected_data, family=&quot;binomial&quot;) # tidy model outputs or_selected &lt;- lgr_model_selected %&gt;% tidy(exponentiate=TRUE, conf.int=TRUE) %&gt;% filter(term == &quot;a&quot;) %&gt;% select(estimate, conf.low, conf.high) # output as table or_selected %&gt;% knitr::kable(caption = &quot;Estimated odds ratio in selected sample&quot;) Table 3.2: Estimated odds ratio in selected sample estimate conf.low conf.high 1.577843 1.494616 1.665406 3.1.1 Bias formulas One option is to apply bias formulas for the odds ratio. \\[ OR_{BiasAdjusted} = OR_{Observed}\\frac{S_{01}S_{10}}{S_{00}S_{11}} \\] Given that the data was simulated we know the selection probabilities (\\(S11=0.7\\), \\(S01=1\\), \\(S10=0.9\\), \\(S00=1\\)) and can directly plug them in to estimate a bias-adjusted odds ratio. However, in practice we will not know these probabilities and will typically specify a range of values, or for probabilistic bias analysis a distribution of values. # define bias parameters S11 &lt;- 0.7 S01 &lt;- 1 S10 &lt;- 0.9 S00 &lt;- 1 # apply bias formula bias_adjusted_or &lt;- or_selected %&gt;% mutate(across(c(estimate, conf.low, conf.high), ~ .x * (S01*S10)/(S11*S00))) # output as table bias_adjusted_or %&gt;% knitr::kable(caption = &quot;Bias-adjusted odds ratio&quot;) Table 3.3: Bias-adjusted odds ratio estimate conf.low conf.high 2.028656 1.92165 2.141236 3.1.2 Weighting Alternatively, we can weight the individual records by the inverse probability of selection and use bootstapping to calculate a confidence interval library(boot) # Add weights selected_data_with_weights &lt;- selected_data %&gt;% mutate(prob_select = a*y*S11 + (1-a)*y*S01 + a*(1-y)*S10 + (1-a)*(1-y)*S00) %&gt;% mutate(inverse_prob = 1/prob_select) # define function to estimate weighted odds ratio (needed for bootstrap function) calculate_weighted_or &lt;- function(weighted_data, i) { weighted_lgr &lt;- glm(y ~ x + a, family=&quot;binomial&quot;, data=weighted_data[i,], weights=inverse_prob) weighted_or &lt;- coef(weighted_lgr)[[&quot;a&quot;]] %&gt;% exp() return(weighted_or) } # set seed of random number generator to ensure reproducibility set.seed(747) # bootstrap calculation of confidence intervals bootstrap_estimates &lt;- boot(selected_data_with_weights, calculate_weighted_or, R=1000) # calculate bias-adjusted point estimate using entire selected subsample point_estimate &lt;- calculate_weighted_or(selected_data_with_weights, 1:nrow(selected_data_with_weights)) # calculate percentile bootstrap confidence interval conf_int &lt;- quantile(bootstrap_estimates$t, c(0.025, 0.975)) # output bias-adjusted estimate tibble(estimate=point_estimate, conf.low=conf_int[[1]], conf.high=conf_int[[2]]) %&gt;% knitr::kable() If we expect selection probabilities to differ within levels of covariates then we can specify different selection probabilities for different strata of covariates. 3.2 Misclassification We will now consider some quantitative bias analysis methods for misclassification of a binary outcome. Similar approaches can be applied for misclassification of a binary exposure. With differential misclassification of the outcome, \\(m_y\\), the odds ratio is biased. # load data misclassified_data &lt;- read_csv(&quot;data/simulated_data.csv&quot;) %&gt;% select(x,a,m_y,s) # fit logistic regression model with misclassified outcome lgr_model_misclassified &lt;- glm(m_y ~ x + a, data=misclassified_data, family=&quot;binomial&quot;) # tidy model outputs or_misclassified &lt;- lgr_model_misclassified %&gt;% tidy(exponentiate=TRUE, conf.int=TRUE) %&gt;% filter(term == &quot;a&quot;) %&gt;% select(estimate, conf.low, conf.high) # output as table or_misclassified %&gt;% knitr::kable(caption = &quot;Estimated odds ratio with misclassified outcome&quot;) Table 3.4: Estimated odds ratio with misclassified outcome estimate conf.low conf.high 1.737071 1.650733 1.827756 3.2.1 Bias formulas Bias formulas for misclassification typically apply to 2x2 tables or 2x2 tables stratified by covariates and require us to specify the bias parameters of sensitivity and specificity. Given that the data was simulated, we know that sensitivity and specificity among the treated were 80% and 99%, and that sensitivity and specificity among the unexposed were 100%. In practice, we do not know these values, but can estimate them using validation studies and specify a range or, for probabilistic bias analysis, distribution of plausible values. Table 3.5: Observed 2x2 table A=1 A=0 Y*=1 a b Y*=0 c d Table 3.6: Corrected 2x2 table A=1 A=0 Y=1 A B Y=0 C D # specify bias parameters sensitivity_a0 &lt;- 1 sensitivity_a1 &lt;- 0.8 specificity_a0 &lt;- 1 specificity_a1 &lt;- 0.99 # define function to correct 2x2 table correct_two_by_two &lt;- function(a, b, c, d, sensitivity_a0, sensitivity_a1, specificity_a0, specificity_a1) { A &lt;- (a - (a + c)*(1-specificity_a1))/(sensitivity_a1 + specificity_a1 - 1) B &lt;- (b - (b + d)*(1-specificity_a0))/(sensitivity_a0 + specificity_a0 - 1) C &lt;- a + c - A D &lt;- b + d - B return(c(&quot;A&quot;=A,&quot;B&quot;=B,&quot;C&quot;=C,&quot;D&quot;=D)) } # extract 2x2 table values a_x0 &lt;- misclassified_data %&gt;% filter(m_y==1, a==1, x==0) %&gt;% nrow() b_x0 &lt;- misclassified_data %&gt;% filter(m_y==1, a==0, x==0) %&gt;% nrow() c_x0 &lt;- misclassified_data %&gt;% filter(m_y==0, a==1, x==0) %&gt;% nrow() d_x0 &lt;- misclassified_data %&gt;% filter(m_y==0, a==0, x==0) %&gt;% nrow() a_x1 &lt;- misclassified_data %&gt;% filter(m_y==1, a==1, x==1) %&gt;% nrow() b_x1 &lt;- misclassified_data %&gt;% filter(m_y==1, a==0, x==1) %&gt;% nrow() c_x1 &lt;- misclassified_data %&gt;% filter(m_y==0, a==1, x==1) %&gt;% nrow() d_x1 &lt;- misclassified_data %&gt;% filter(m_y==0, a==0, x==1) %&gt;% nrow() # correct 2x2 table corr_two_by_two_x0 &lt;- correct_two_by_two(a_x0, b_x0, c_x0, d_x0, sensitivity_a0, sensitivity_a1, specificity_a0, specificity_a1) corr_two_by_two_x1 &lt;- correct_two_by_two(a_x1, b_x1, c_x1, d_x1, sensitivity_a0, sensitivity_a1, specificity_a0, specificity_a1) # calculate Mantel-Haenszel odds ratio numerator &lt;- corr_two_by_two_x1[[1]]*corr_two_by_two_x1[[4]]/sum(corr_two_by_two_x1) + corr_two_by_two_x0[[1]]*corr_two_by_two_x0[[4]]/sum(corr_two_by_two_x0) denominator &lt;- corr_two_by_two_x1[[2]]*corr_two_by_two_x1[[3]]/sum(corr_two_by_two_x1) + corr_two_by_two_x0[[2]]*corr_two_by_two_x0[[3]]/sum(corr_two_by_two_x0) mh_estimate &lt;- numerator/denominator print(mh_estimate) ## [1] 2.003725 We can use bootstrapping to calculate a confidence interval. 3.2.2 Record-level correction For record-level correction we can as before calculate two by two tables, but as a second step use these to 3.2.3 Probabalistic bias analysis 3.3 Unmeasured confounding "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
